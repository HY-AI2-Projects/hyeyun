# DETR:End-to-End-Object-Detection-with-Transformers

- 2023-2 ì¸ê³µì§€ëŠ¥2 ê¸°ë§ê³¼ì œ(ì •í˜œìœ¤ 2020003945)

- ë³¸ ê²Œì‹œë¬¼ì€ DETR ë…¼ë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ, ë”¥ëŸ¬ë‹ ê¸°ì´ˆì§€ì‹ì´ ìˆëŠ” ì´ˆë³´ìë“¤ì´ DETR ëª¨ë¸ì— ëŒ€í•´ ë³´ë‹¤ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì‘ì„±í•œ ë¬¸ì„œì…ë‹ˆë‹¤.

- ë…¼ë¬¸ ì›ë³¸ê³¼ ì˜ˆì‹œ ì½”ë“œë¥¼ ì¶”ê°€ ìë£Œë¡œ ì²¨ë¶€í•˜ì˜€ìŠµë‹ˆë‹¤.


## ğŸ·ï¸ Introduction

DETR(End-to-End Object Detection with Transformers)ì€ Facebook Research íŒ€ì´ 2020ë…„ 8ì›”ì— ì»´í“¨í„° ë¹„ì „ í•™íšŒì¸ ECCVì—ì„œ ë°œí‘œí•œ ë…¼ë¬¸ì…ë‹ˆë‹¤. DETRì€ Transformer êµ¬ì¡°ë¥¼ í™œìš©í•˜ì—¬, end-to-endë¡œ object detectionì„ ìˆ˜í–‰í•˜ë©´ì„œë„ ë†’ì€ ì„±ëŠ¥ì„ ë³´ì˜€ìŠµë‹ˆë‹¤. ê¸°ì¡´ object detection ë°©ë²•ë¡ ì€ prior knowledgeê°€ ë§ì´ ìš”êµ¬ë˜ì—ˆê³ , NMS(Non Maximum Suppression)ê³¼ ê°™ì€ post-processing ê³¼ì •ì´ ë°˜ë“œì‹œ í•„ìš”í–ˆìŠµë‹ˆë‹¤. ë°˜ë©´ DETRì€ object detectionì„ ì§ì ‘ set prediction ë¬¸ì œë¡œ ì ‘ê·¼í•©ë‹ˆë‹¤. í˜„ì¬ ë§ì€ SOTA ëª¨ë¸ë“¤ì´ DETRì„ ê¸°ë°˜ìœ¼ë¡œ ë°œì „í•œë§Œí¼, ë°˜ë“œì‹œ ì½ì–´ì•¼í•˜ëŠ” ê¸°ë…ë¹„ì ì¸ ë…¼ë¬¸ì´ë¼ê³  í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 



## ğŸ·ï¸ Contribution 

ë³¸ ë…¼ë¬¸ì—ì„œ ì£¼ì¥í•˜ëŠ” contributionì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

1. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” object detectionì„ direct set predictionìœ¼ë¡œ ì •ì˜í•˜ì—¬, transformerì™€ bipartite matching loss(ì´ë¶„ë§¤ì¹­)ë¥¼ ì‚¬ìš©í•œ DETR(DEtection TRansformer)ì„ ì œì•ˆí•©ë‹ˆë‹¤. 
2. DETRì€ COCO datasetì— ëŒ€í•˜ì—¬ Faster R-CNNê³¼ ë¹„ìŠ·í•œ ìˆ˜ì¤€ì˜ ì„±ëŠ¥ì„ ë³´ì…ë‹ˆë‹¤. 
3. ì¶”ê°€ì ìœ¼ë¡œ, self-attentionì„ í†µí•œ global information(ì „ì—­ ì •ë³´)ë¥¼ í™œìš©í•¨ìœ¼ë¡œì¨ í¬ê¸°ê°€ í° ê°ì²´ë¥¼ Faster R-CNNë³´ë‹¤ í›¨ì”¬ ì˜ í¬ì°©í•©ë‹ˆë‹¤.



## ğŸ·ï¸ Method 

ë³¸ ë…¼ë¬¸ì—ì„œëŠ” object detection ì‹œ direct set predictionì„ ìœ„í•´ ë‘ ê°€ì§€ ìš”ì†Œê°€ í•„ìˆ˜ì ì´ë¼ê³  í•©ë‹ˆë‹¤. 

(1) predicted bounding boxì™€ ground truth box ì‚¬ì´ì˜ unique matchingì„ ê°€ëŠ¥í•˜ë„ë¡ í•˜ëŠ” set prediction loss

(2) í•œ ë²ˆì˜ forward passë¡œ object model ì‚¬ì´ì˜ relationì„ ì˜ˆì¸¡í•˜ëŠ” architecture


**1. Object detection set prediction loss**

DETRì€ ë¨¼ì € ì¶©ë¶„íˆ í° Nê°œ ì¢…ë¥˜ì˜ predictionsì´ ì´ë£¨ì–´ì§„ë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤. ê·¸ëŸ¬ê³  ë‚˜ì„œ ì˜ˆì¸¡ëœ ê°’ê³¼ ì‹¤ì œê°’ì„ ì´ë¶„ ë§¤ì¹­í•˜ê²Œë˜ê³ , ì´ë¥¼ ìµœì í™”í•˜ê²Œ ë©ë‹ˆë‹¤. ì´ë¥¼ ìœ„í•œ ìˆ˜ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.

   
![image](https://github.com/HY-AI2-Projects/hyeyun/assets/104217871/ee77aaae-72d0-4ed0-956d-bfdd7bfd8185)


ìˆ˜ì‹ì„ ì‚´í´ë³´ë©´, y hat ê°’ì€ ì˜ˆì¸¡ê°’ ì§‘í•©, ê·¸ëƒ¥ y ê°’ì€ ì‹¤ì œê°’ ì§‘í•©ì…ë‹ˆë‹¤. ê·¸ë˜ì„œ ë§¤ì¹­ loss ê°’ì˜ í•©ì„ ê°€ì¥ ì‘ê²Œ ë§Œë“¤ì–´ì£¼ëŠ” sigmaë¥¼ ì°¾ì•„ì£¼ë©´ ë˜ëŠ”ë°, ì—¬ê¸°ì„œ sigmaëŠ” ë§ ê·¸ëŒ€ë¡œ ë§¤ì¹­ëœ ê²°ê³¼ë¡œ ë³¼ ìˆ˜ ìˆê² ìŠµë‹ˆë‹¤.
ë§¤ì¹­ëœ loss ê°’ì€ pair-wiseí•œ matching costì…ë‹ˆë‹¤.
ê²°ê³¼ì ìœ¼ë¡œ sigmaë¥¼ ì°¾ëŠ” taskëŠ” ìµœì  í• ë‹¹ ë¬¸ì œë¡œ ìƒê°í•  ìˆ˜ ìˆê³ , ë‹¤ì‹œ ë§í•´ ê°€ì¤‘ ì´ë¶„ ë§¤ì¹­ì…ë‹ˆë‹¤. ì´ëŠ” Hungarian algorithmì— ë”°ë¼ ì´ë£¨ì–´ì§‘ë‹ˆë‹¤.
í•´ë‹¹ Taskë¥¼ ìˆ˜í–‰í•˜ë©´ì„œ ê²°ê³¼ì ìœ¼ë¡œ ìƒì„±ë˜ëŠ” outputì€ Classì™€ Bounding boxesê°€ ë‚˜ì˜µë‹ˆë‹¤. ê·¸ë¦¬ê³  Bounding boxëŠ” ì¼ë°˜ì ìœ¼ë¡œ ì¤‘ì‹¬ ì¢Œí‘œ, ë†’ì´, ë„ˆë¹„ì— ëŒ€í•œ ì •ë³´ë¥¼ ë‹´ìŠµë‹ˆë‹¤. ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Bounding box ê´€ë ¨ ê°’ë“¤ì„ 0ê³¼ 1 ì‚¬ì´ë¡œ normalize í•©ë‹ˆë‹¤.

ë§¤ì¹­ëœ loss ê°’ì˜ ìˆ˜ì‹ë„ ì¡´ì¬í•˜ëŠ”ë°, ì´ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.


![image](https://github.com/HY-AI2-Projects/hyeyun/assets/104217871/f14f88fd-c1f8-4938-8130-1cd433f25bc7)


ì´ëŠ” classê°€ ì˜ ë§ê³ , bounding box ë˜í•œ ì˜ ë§í˜”ë‹¤ë©´ Loss ê°’ì´ ì¤„ì–´ë“œëŠ” í˜•íƒœë¥¼ ë•ë‹ˆë‹¤.

Bounding boxì— ëŒ€í•œ Loss ìˆ˜ì‹ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.


![image](https://github.com/HY-AI2-Projects/hyeyun/assets/104217871/1aaa24c5-8946-4355-aa6c-cabf8678c5fd)


ì „ì, ì¦‰ iouì— ëŒ€í•œ LossëŠ” í¬ê¸°ì™€ ìƒê´€ì—†ì´ bounding boxë¥¼ ë§ì´ ê²¹ì¹  ìˆ˜ ìˆë„ë¡ í•´ì¤ë‹ˆë‹¤. ê·¸ë¦¬ê³  L1ì— ëŒ€í•œ Loss ê°’ ë˜í•œ ë‘ ê°œì˜ bounding boxê°€ ìœ ì‚¬í•´ì§€ë„ë¡ í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ëŒ€ì‹  í¬ê¸°ì— ì˜í–¥ì„ ë°›ê³¤ í•©ë‹ˆë‹¤. ìœ„ì—ì„œ ì‚´í´ë³¸ ì´ë¶„ ë§¤ì¹­ì„ í†µí•´ ê¸°ì¡´ region proposal í˜¹ì€ anchorì™€ ê°™ì€ heuristicí•œ ë°©ë²•ë¡ ê³¼ë„ ì˜ ë§ëŠ”ë‹¤ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì´ë¶„ ë§¤ì¹­ì˜ ê²°ê³¼ë¡œ set predictionì˜ ì¤‘ë³µëœ ê²°ê³¼ë¥¼ í”¼í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤.

ì•ì„œ ë§í•œ ë‚´ìš©ì„ ì¢…í•©í•œ ì „ì²´ Hungarian LossëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì •ë¦¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.


![image](https://github.com/HY-AI2-Projects/hyeyun/assets/104217871/5d3493be-af6f-4592-9380-0b0b47e29aa4)



**2. DETR architecture**

![image](https://github.com/HY-AI2-Projects/hyeyun/assets/104217871/db04ce4c-a7a2-4c7a-bf26-04a95e76ddff)

DETRì€ ***1) CNN backbone, 2) Transformer encoder, 3) Transformer decoder, 4) FFN(Feed Forward Network)*** ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. 

***1) CNN backbone***

   ë¨¼ì € ì…ë ¥ì´ë¯¸ì§€ ![image](https://github.com/HY-AI2-Projects/hyeyun/assets/104217871/ac728a3f-3d18-4db3-ab6d-d994a2da5330)ë¥¼ CNN backbone networkì— ì…ë ¥í•˜ì—¬, feature map ![image](https://github.com/HY-AI2-Projects/hyeyun/assets/104217871/1a2d1148-4f75-421a-a0a3-21fc8b0f2ae6)ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì´ ë•Œ C=2048ì´ë©°, ![image](https://github.com/HY-AI2-Projects/hyeyun/assets/104217871/8722aad0-ea09-4fb8-a09d-35526dd13ecf) ì…ë‹ˆë‹¤. 

  
***2) Transformer encoder***

ì´í›„ 1x1 convolution ì—°ì‚°ì„ ì ìš©í•˜ì—¬, Cì°¨ì›ì˜ feature mapì„ dì°¨ì›ìœ¼ë¡œ ê°ì†Œì‹œì¼œ ìƒˆë¡œìš´ feature map![image](https://github.com/HY-AI2-Projects/hyeyun/assets/104217871/e37fc70c-9a4d-471d-8092-a381e1673d19) ì„ ìƒì„±í•©ë‹ˆë‹¤. Transformer encoderëŠ” sequenceë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ê¸° ë•Œë¬¸ì— z0ì˜ spatial dimensionì„ collapse(=flatten)í•˜ì—¬ í¬ê¸°ë¥¼ dÃ—HWë¡œ ë³€ê²½ì‹œì¼œì¤ë‹ˆë‹¤. ê° encoder layerëŠ” multi-head self-atttention moduleê³¼ feed forward network(FFN)ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. Transformer êµ¬ì¡°ëŠ” ì…ë ¥ embeddingì˜ ìˆœì„œì™€ ìƒê´€ì—†ì´ ê°™ì€ ì¶œë ¥ê°’ì„ ìƒì„±í•˜ëŠ” permutation-invariant ì†ì„±ì´ ìˆê¸° ë•Œë¬¸ì— encoder layer ì…ë ¥ ì „ì— ì…ë ¥ embeddingì— positional encodingì„ ë”í•´ì¤ë‹ˆë‹¤. 

   
***3) Transformer decoder***

Transformer decoderëŠ” maskingì„ í†µí•´ ë‹¤ìŒ tokenì„ ì˜ˆì¸¡í•˜ëŠ” autoregressive ë°©ë²•ì„ ì‚¬ìš©í•˜ëŠ” ë°˜ë©´, DETRì˜ decoderëŠ” Nê°œì˜ objectì— ëŒ€í•œ ì •ë³´ë¥¼ í•œë²ˆì— ì¶œë ¥í•©ë‹ˆë‹¤. Decoder ì—­ì‹œ permutation-invariantí•˜ê¸° ë•Œë¬¸ì— ì…ë ¥ìœ¼ë¡œ ë°›ëŠ” embeddingìœ¼ë¡œ object queriesë¼ê³  ë¶ˆë¦¬ëŠ” learnt positional encodingì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
object queryëŠ” object query featureê³¼ object query positional embeddingìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤. object query featureëŠ” decoderì— initial inputìœ¼ë¡œ ì‚¬ìš©ë˜ì–´, decoder layerë¥¼ ê±°ì¹˜ë©´ì„œ í•™ìŠµë©ë‹ˆë‹¤. query positional embeddingì€ decoder layerì—ì„œ attention ì—°ì‚° ì‹œ ëª¨ë“  query featureì— ë”í•´ì§‘ë‹ˆë‹¤. query featureëŠ” í•™ìŠµ ì‹œì‘ ì‹œ 0ìœ¼ë¡œ ì´ˆê¸°í™”(zero-initialized)ë˜ë©°, query positional embeddingì€ í•™ìŠµ ê°€ëŠ¥(learnable)í•©ë‹ˆë‹¤. ì´ëŸ¬í•œ object queriesëŠ” ê¸¸ì´ê°€ Nìœ¼ë¡œ, decoderì— ì˜í•´ output embeddingìœ¼ë¡œ ë³€í™˜(transform)ë˜ë©° ì´í›„ FFNì„ í†µí•´ ê°ê° ë…ë¦½ì ìœ¼ë¡œ(independently) box coordinateì™€ class labelë¡œ decodeë©ë‹ˆë‹¤. ì´ëŠ” ê°ê°ì˜ object queryëŠ” í•˜ë‚˜ì˜ ê°ì²´ë¥¼ ì˜ˆì¸¡í•˜ëŠ” region proposalì— ëŒ€ì‘ëœë‹¤ê³  ë³¼ ìˆ˜  ìˆìŠµë‹ˆë‹¤. ì¦‰, object queriesëŠ” Nê°œì˜ ê°ì²´ë¥¼ ì˜ˆì¸¡í•˜ê¸° ìœ„í•œ ì¼ì¢…ì˜ prior knowledgeë¡œë„ ë³¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
encoderì™€ ìœ ì‚¬í•˜ê²Œ object queryë¥¼ ê° attention layerì˜ ì…ë ¥ì— ë”í•´ì¤ë‹ˆë‹¤. ì´ ë•Œ embeddingì€ self-attentionê³¼ encoder-decoder attentionì„ í†µí•´ ì´ë¯¸ì§€ ë‚´ ì „ì²´ contextì— ëŒ€í•œ ì •ë³´ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ ê°ì²´ ì‚¬ì´ì˜ pair-wise relationì„ í¬ì°©í•˜ì—¬ ê°ì²´ê°„ì˜ ì „ì—­ì (global)ì¸ ì •ë³´ë¥¼ ëª¨ë¸ë§í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•´ì§‘ë‹ˆë‹¤. 

   
***4) FFN(Feed Forward Network)***

Decoderì—ì„œ ì¶œë ¥í•œ output embeddingì„ 3ê°œì˜ linear layerì™€ ReLU activation functionìœ¼ë¡œ êµ¬ì„±ëœ FFNì— ì…ë ¥í•˜ì—¬ ìµœì¢… ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. FFNì€ ì´ë¯¸ì§€ì— ëŒ€í•œ class labelê³¼ bounding boxì— ì¢Œí‘œ(normalized center coordinate, width, height)ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤. ì´ ë•Œ ì˜ˆì¸¡í•˜ëŠ” class label ì¤‘ âˆ…ì€ ê°ì²´ê°€ í¬ì°©ë˜ì§€ ì•Šì€ ê²½ìš°ë¡œ, "background" classë¥¼ ì˜ë¯¸í•©ë‹ˆë‹¤.

ì¶”ê°€ì ìœ¼ë¡œ ë³¸ ë…¼ë¬¸ì—ì„œëŠ” Auxiliary decoding lossesë¥¼ ì‚¬ìš©í•´ì„œ ì„±ëŠ¥ì„ ë†’ì˜€ë‹¤ê³  í•©ë‹ˆë‹¤.


## ğŸ·ï¸ Model Zoo


ì €ìë“¤ì€ ìš°ì„  Object Detection baselineìœ¼ë¡œ DETRê³¼ DETR-DC5 ëª¨ë¸ì„ ì œê³µí•©ë‹ˆë‹¤. ì„±ëŠ¥(AP) ì€ COCO 2017 val5kì„ ì‚¬ìš©í•´ í‰ê°€í–ˆìœ¼ë©°, ì‹¤í–‰ ì‹œê°„(Inference Time) ì€ ì²« 100ê°œì˜ ì´ë¯¸ì§€ì— ëŒ€í•´ ì¸¡ì •ë©ë‹ˆë‹¤.

<table>
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>backbone</th>
      <th>schedule</th>
      <th>inf_time</th>
      <th>box AP</th>
      <th>url</th>
      <th>size</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>DETR</td>
      <td>R50</td>
      <td>500</td>
      <td>0.036</td>
      <td>42.0</td>
      <td><a href="https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth">model</a>&nbsp;|&nbsp;<a href="https://dl.fbaipublicfiles.com/detr/logs/detr-r50_log.txt">logs</a></td>
      <td>159Mb</td>
    </tr>
    <tr>
      <th>1</th>
      <td>DETR-DC5</td>
      <td>R50</td>
      <td>500</td>
      <td>0.083</td>
      <td>43.3</td>
      <td><a href="https://dl.fbaipublicfiles.com/detr/detr-r50-dc5-f0fb7ef5.pth">model</a>&nbsp;|&nbsp;<a href="https://dl.fbaipublicfiles.com/detr/logs/detr-r50-dc5_log.txt">logs</a></td>
      <td>159Mb</td>
    </tr>
    <tr>
      <th>2</th>
      <td>DETR</td>
      <td>R101</td>
      <td>500</td>
      <td>0.050</td>
      <td>43.5</td>
      <td><a href="https://dl.fbaipublicfiles.com/detr/detr-r101-2c7b67e5.pth">model</a>&nbsp;|&nbsp;<a href="https://dl.fbaipublicfiles.com/detr/logs/detr-r101_log.txt">logs</a></td>
      <td>232Mb</td>
    </tr>
    <tr>
      <th>3</th>
      <td>DETR-DC5</td>
      <td>R101</td>
      <td>500</td>
      <td>0.097</td>
      <td>44.9</td>
      <td><a href="https://dl.fbaipublicfiles.com/detr/detr-r101-dc5-a2e86def.pth">model</a>&nbsp;|&nbsp;<a href="https://dl.fbaipublicfiles.com/detr/logs/detr-r101-dc5_log.txt">logs</a></td>
      <td>232Mb</td>
    </tr>
  </tbody>
</table>


ì´ ëª¨ë¸ì€ torch hubë¥¼ í†µí•´ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. 

```python
model = torch.hub.load('facebookresearch/detr:main', 'detr_resnet50', pretrained=True)
```

ë˜í•œ, Panoptic segmentation ëª¨ë¸ë„ ì œê³µí•©ë‹ˆë‹¤.


<table>
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>name</th>
      <th>backbone</th>
      <th>box AP</th>
      <th>segm AP</th>
      <th>PQ</th>
      <th>url</th>
      <th>size</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>DETR</td>
      <td>R50</td>
      <td>38.8</td>
      <td>31.1</td>
      <td>43.4</td>
      <td><a href="https://dl.fbaipublicfiles.com/detr/detr-r50-panoptic-00ce5173.pth">download</a></td>
      <td>165Mb</td>
    </tr>
    <tr>
      <th>1</th>
      <td>DETR-DC5</td>
      <td>R50</td>
      <td>40.2</td>
      <td>31.9</td>
      <td>44.6</td>
      <td><a href="https://dl.fbaipublicfiles.com/detr/detr-r50-dc5-panoptic-da08f1b1.pth">download</a></td>
      <td>165Mb</td>
    </tr>
    <tr>
      <th>2</th>
      <td>DETR</td>
      <td>R101</td>
      <td>40.1</td>
      <td>33</td>
      <td>45.1</td>
      <td><a href="https://dl.fbaipublicfiles.com/detr/detr-r101-panoptic-40021d53.pth">download</a></td>
      <td>237Mb</td>
    </tr>
  </tbody>
</table>


## ğŸ·ï¸ Notebooks

ì €ìë“¤ì€ DETRì— ëŒ€í•œ ì´í•´ë¥¼ ë•ê¸° ìœ„í•´ colabì—ì„œ ëª‡ ê°€ì§€ì˜ notebookì„ ì œê³µí•©ë‹ˆë‹¤.

* [DETR's hands on Colab Notebook](https://colab.research.google.com/github/facebookresearch/detr/blob/colab/notebooks/detr_attention.ipynb):
  
1. hubì—ì„œ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ëŠ” ë°©ë²•
2. ì˜ˆì¸¡ì„ ìƒì„±í•˜ëŠ” ë°©ë²•
3. ëª¨ë¸ì˜ attentionì„ ì‹œê°í™”í•˜ëŠ” ë°©ë²•(ë…¼ë¬¸ì˜ figureì™€ ìœ ì‚¬)


* [Standalone Colab Notebook](https://colab.research.google.com/github/facebookresearch/detr/blob/colab/notebooks/detr_demo.ipynb):
  
1. ê°€ì¥ ê°„ë‹¨í•œ ë²„ì „ì˜ DETRì„ 50 lines of python codeë¡œ ì‹¤í–‰í•˜ëŠ” ë°©ë²•
2. ì˜ˆì¸¡ì„ ì‹œê°í™”í•˜ëŠ” ë°©ë²•


* [Panoptic Colab Notebook](https://colab.research.google.com/github/facebookresearch/detr/blob/colab/notebooks/DETR_panoptic.ipynb):
  
1. Panoptic segmentationì„ ìœ„í•œ DETRì„ ì‚¬ìš©í•˜ëŠ” ë°©ë²•
2. ì˜ˆì¸¡ì„ ì‹œê°í™”í•˜ëŠ” ë°©ë²•


## ğŸ·ï¸ Usage - Object detection

DETRì€ ìœ„ì—ì„œ ê¸°ìˆ í–ˆë˜ ëŒ€ë¡œ ê¸°ì¡´ì˜ íŒ¨í‚¤ì§€ë“¤ì— í¬ê²Œ ì˜ì¡´ì ì´ì§€ ì•ŠìŠµë‹ˆë‹¤. ì „ë°˜ì ì¸ ì„¤ì¹˜ íŒŒì´í”„ë¼ì¸ì€ ì•„ë˜ì™€ ê°™ìŠµë‹ˆë‹¤.

1. Repository clone:
```
git clone https://github.com/facebookresearch/detr.git
```
2. install PyTorch 1.5+ and torchvision 0.6+:
```
conda install -c pytorch pytorch torchvision
```
3. Install pycocotools (for evaluation on COCO) and scipy (for training):
```
conda install cython scipy
pip install -U 'git+https://github.com/cocodataset/cocoapi.git#subdirectory=PythonAPI'
```
pycocotollsëŠ” COCO datasetì— evaluationì„ í•˜ê¸° ìœ„í•œ íˆ´ì…ë‹ˆë‹¤.

(optional) install panopticapi:
```
pip install git+https://github.com/cocodataset/panopticapi.git
```

## ğŸ·ï¸ Data preparation

ë³¸ ì—°êµ¬ì—ì„œ ëŒ€í‘œì ìœ¼ë¡œ ì‚¬ìš©í•œ datasetì€ COCO 2017ì…ë‹ˆë‹¤. ì£¼ì„(annotation)ì´ í¬í•¨ëœ train/val imageëŠ”
[http://cocodataset.org](http://cocodataset.org/#download)ì—ì„œ ë‹¤ìš´ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. í•´ë‹¹ datasetì˜ structureëŠ” ì•„ë˜ì™€ ê°™ì•„ì•¼ í•©ë‹ˆë‹¤.

```
path/to/coco/
  annotations/  # annotation json files
  train2017/    # train images
  val2017/      # val images
```

## ğŸ·ï¸ Training
ì˜ˆì‹œë¡œ node ë‹¹ 8 gpusë¥¼ ì‚¬ìš©í•´ 300 epochì„ í•™ìŠµì‹œí‚¬ ê²½ìš° ì•„ë˜ì™€ ê°™ì€ ëª…ë ¹ì–´ë¥¼ ì‚¬ìš©í•˜ë©´ ë©ë‹ˆë‹¤.:
```
python -m torch.distributed.launch --nproc_per_node=8 --use_env main.py --coco_path /path/to/coco 
```
1 epochì€ 28ë¶„ ì •ë„ ê±¸ë¦¬ê¸°ì—, 300 epochì€ 6ì¼ì •ë„ ê±¸ë¦´ ìˆ˜ ìˆìŠµë‹ˆë‹¤(V100 ê¸°ì¤€).
ê²°ê³¼ ì¬ìƒì‚°ì„ ìš©ì´í•˜ê¸° í•˜ê¸° ìœ„í•´ ì €ìë“¤ì€ 150 epoch scheduleì— ëŒ€í•œ results and training logs
[results and training logs](https://gist.github.com/szagoruyko/b4c3b2c3627294fc369b899987385a3f)ë¥¼ ì œê³µí•©ë‹ˆë‹¤(39.5/60.3 AP/AP50).

ì €ìë“¤ì€ transformerë¥¼ í•™ìŠµí•˜ëŠ” ë° 1e-4ì˜ í•™ìŠµë¥ ì„, backboneì„ í•™ìŠµí•˜ëŠ”ë° 1e-5ì˜ í•™ìŠµë¥ ì„ ì ìš©í•œ AdamWì„ DETR í•™ìŠµì— ì ìš©í•©ë‹ˆë‹¤. Augmentaitonì„ ìœ„í•´ Horizontal flips, scales, cropsê°€ ì“°ì˜€ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ë“¤ì€ ìµœì†Œ 800, ìµœëŒ€ 1333ì˜ sizeë¥¼ ê°–ê²Œë” rescaledë©ë‹ˆë‹¤. TransformerëŠ” 0.1ì˜ dropoutì„, ì „ì²´ ëª¨ë¸ì€ 0.1ì˜ grad clipì„ ì‚¬ìš©í•´ í•™ìŠµë©ë‹ˆë‹¤.


## ğŸ·ï¸ Evaluation
DETR R50ì„ COCO val5kì— ëŒ€í•´ í‰ê°€í•˜ê³  ì‹¶ìœ¼ë©´ ì•„ë˜ì™€ ê°™ì€ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´ ë©ë‹ˆë‹¤.:
```
python main.py --batch_size 2 --no_aux_loss --eval --resume https://dl.fbaipublicfiles.com/detr/detr-r50-e632da11.pth --coco_path /path/to/coco
```
ëª¨ë“  DETR detection modelì— ëŒ€í•œ í‰ê°€ ê²°ê³¼ëŠ” ì œê³µí•©ë‹ˆë‹¤.[gist](https://gist.github.com/szagoruyko/9c9ebb8455610958f7deaa27845d7918).
ë‹¨, GPU ë‹¹ batch size(number of images)ì— ë”°ë¼ ê²°ê³¼ê°€ ìƒë‹¹íˆ ë³€í•©ë‹ˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, batch size 1ë¡œ í•™ìŠµí•œ DC5 ëª¨ë¸ì˜ ê²½ìš° GPU ë‹¹ 1ê°œ ì´ìƒì˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•´ í‰ê°€í•  ê²½ìš° ì„±ëŠ¥ì´ êµ‰ì¥íˆ ë‚®ê²Œ ë‚˜ì˜µë‹ˆë‹¤.

## ğŸ·ï¸ Reference 
- https://github.com/facebookresearch
